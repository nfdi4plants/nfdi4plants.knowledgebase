---
title: Validate, Review & Publish your ARC
sidebar:
  order: 11
lastUpdated: 2025-10-15
authors:
  - saskia-hiltemann
  - kathryn-dumschott
  - sabrina-zander
  - stella-eggels
  - ursula-eberhardt
  - dominik-brilhaus
---

import { Steps } from '@astrojs/starlight/components';
import { Card } from '@astrojs/starlight/components';

import {Content as ValidateARC} from '../start-here/validate-arc.mdx';
import {Content as PublishARC} from '../start-here/publish-arc.mdx';


<ValidateARC />


## Reviewing your ARC before publication

Before an ARC can be published, it must clearly and completely describe the data it contains. In this guide we outline things to consider before submitting your ARC for publication.

### Check the ARC repository on DataHUB

First, check the ARC's top level information:

<Card icon="pen" title="DataHUB repository">
    <Steps>

    1. Open your ARC on [PLANTDataHUB](https://git.nfdi4plants.org)
    2. Is the name of the repository descriptive?
    3. The repository should be set to public. This is currently the best way to ensure that the people reviewing the corresponding publication have access to the ARC. Check the visibility by looking at the icon behind the repository name. 
       - You can change the visibility under `Settings -> General -> Visibility, project features, permissions`. 
    4. The ARC should have a `README.md` with useful information? This is the first thing people will see when they look at your ARC on DataHUB and is a useful way to 'orientate' the viewer in the ARC. (However, be sure that any important information in the README is also contained within the actual ARC structure in order to adhere to the ISA framework.)
    5. Does your repository have a `LICENSE` file? This is required to allow re-use of your ARC. [Follow these instructions and recommendations](/nfdi4plants.knowledgebase/datahub/arc-features/datahub-arc-license) to add an open license such as `MIT` or `Creative Commons` to your ARC. [IMPORTANT]
    6. Check the **Project Storage** on the right side. Is most of the storage space "LFS" storage? As a rule of thumb, the usage under "Repository" storage should be less than 1 GB.

    </Steps>
</Card>

### Check the ARC (e.g. in ARCitect)

Next, open the ARC itself, and run through everything one last time, or else ask a friend or colleague to have a look at your ARC to make sure it's understandable.

<Card icon="pen" title="Investigation">
    <Steps>
    1. The title and description should be clear and informative.
    2. Check the contacts. Are all collaborators included? Is all data (name, email, ORCiD, affiliation) for the contacts correct and complete?

    </Steps>
</Card>

<Card icon="pen" title="Studies and Assays">
For each study and assay in your ARC, check that:
    <Steps>
    1. The top-level metadata is present and informative, including the measurement/technology metadata (in the case of assays).
    2. Within all annotation tables:
       - Columns use ontology terms where possible.
       - Column types (e.g. characteristic, parameter, factor) are correct. See the [Annotation Principles](/nfdi4plants.knowledgebase/core-concepts/isa-annotation-principles/#characteristics) for more details.
       - Fixed ISA Column headers (e.g. Protocol REF) may not be manually renamed.
       - Input column headers match the 'type' of input in the column (this can be `Input[Source Name]`, `Input[Sample Name]`, `Input[Material]`, or `Input[Data]`).
       - Output column headers match the 'type' of output in the column (this can be `Output[Source Name]`, `Output[Sample Name]`, `Output[Material]`, or `Output[Data]`).
       - Columns have units (where applicable).
       - The values in the columns make sense (e.g. numerical values in a temperature column), no obvious copy-paste errors, excel dragging errors, missing values, etc.
       - There are no missing columns.
         - Important metadata present in a protocol document has been added to the annotation table.
         - Any community requirements such as templates or validation packages are utilized.
    3. Protocol documents in the `protocols` folder must be referenced in the corresponding annotation sheet via a `Protocol REF` column.
    4. [Assays] The data contained in the `dataset` folder is organised in an understandable way AND is referenced in the 'Output [Data]' column of the corresponding annotation sheet.
    5. [Assays] Check the Datamap if one is present
    6. Make sure that all column headers within a table are unique.
    7. Did you create or make the last editions in your ISA files in MS Excel rather than in one of the ARC tools? Make sure that:
       - Your ISA-tables are tables in the MS Excel sense rather than ranges. Tables should include all lines and rows that are meant to contain Isa-formatted data.
       - To check this, right-click a cell that should belong to the table. If you get the Menu item "Table" > and in sub-menu "convert to range", you are fine. Otherwise, select the all cells of the table, go to the "Insert" tab and select the "Table" button.

    </Steps>
</Card>

<Card icon="pen" title="Runs and Workflows">
    <Steps>
    1. Analysis code is included either as a CWL workflow in the workflows/runs folder, or as a virtual assay.
       See also our [guide on adding data analysis](/nfdi4plants.knowledgebase/start-here/data-analysis)
    2. Was any external data used in the analysis? Is it clear where this came from?
        :::tip
        Follow [this guide](/nfdi4plants.knowledgebase/guides/arc-adding-external-data/) to design a study describing the external data (e.g. downloads from a database or supplemental data from publications)
        :::
    3. [CWL workflow] Ensure that it runs using `cwltool`. See [guide](/nfdi4plants.knowledgebase/start-here/option2-cwl/) for more details.
    4. [Virtual Assay] Code should be in the "protocols" folder, and output data in "dataset" folder. Ensure that the code runs. Typically, the "input" data consumed by the code is already stored somewhere in the ARC, e.g. assay datasets or study resources.
    5. [Virtual Assay] For non-code based data analysis using softwares e.g. for statistics or graphics, we recommend the same logic: describe the data analysis as comprehensible as possible in the "protocols" folder, and provide the resulting data in the "dataset" folder. 

    </Steps>
</Card>

<Card icon="pen" title="All together">
To check the overall consistency of your ARC, make sure that the full connection from sample to raw data to processed data is there.
    <Steps>
    1. For every output, can you trace its origins back through the ARC? Is the provenance of all data fully described?
       - A mermaid graph is a quick way to visualize this provenance, showing how the inputs and outputs from your studies and assays are connected. Learn more about the arcIsaProcessMermaid tool [here](https://www.nuget.org/packages/arcIsaProcessMermaid/#readme-body-tab)
       - The `arc-summary.md` lists the files that are properly linked in the ARC. This is provided as a downloadable artifact by the CI/CD job "Create ARC json".

    </Steps>
</Card>



## Publish your ARC

<PublishARC />
